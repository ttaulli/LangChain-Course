{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5284ede",
   "metadata": {},
   "source": [
    "# LLMRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain,SequentialChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da30bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc020f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15220cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_template=\"\"\"You are a very smart human resources person. \\\n",
    "You are great at answering questions about human resources in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f421da",
   "metadata": {},
   "outputs": [],
   "source": [
    "law_template=\"\"\"You are a very smart lawyer. \\\n",
    "You are great at answering questions about the law in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca50521",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "{\n",
    "    'name':'human resources',\n",
    "    'description':'Answer human resources questions',\n",
    "    'template':hr_template},\n",
    "\n",
    "{\n",
    "    'name':'law',\n",
    "    'description':'Answers legal questions',\n",
    "    'template':law_template}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_info in prompt_infos:\n",
    "    name = p_info['name']\n",
    "    prompt_template = p_info['template']\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm,prompt=prompt)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template('{input}')\n",
    "\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "destinations=[\n",
    "f\"{p['name']}: {p['description']}\" for p in prompt_infos\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12999c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe483ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_str = \"\\n\".join(destinations)\n",
    "\n",
    "print(destination_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destination_str)\n",
    "\n",
    "router_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c75f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = PromptTemplate(template=router_template,\n",
    "input_variables=['input'],\n",
    "output_parser=RouterOutputParser())\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm,router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "destination_chains=destination_chains,\n",
    "default_chain=default_chain,verbose=True)\n",
    "\n",
    "chain.run(\"How do intellectual property laws address the use of AI-generated content?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"How do you handle conflict between team members?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d79918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79ce20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
